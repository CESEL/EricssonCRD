\subsection{Fault Localization through Test Logs}
\label{secLogs}

Identifying the underlying fault from a test failure is challenging. Unlike conducting code review, where developers manually read over the code to directly identify issues~\cite{Rigby2014TOSEM}, a test failure can be a symptom of multiple underlying faults and one fault may lead to multiple test failures. Therefore, the diagnosis of test failures can be time consuming~\cite{Glerum:2009:DLT:1629575.1629586}. This is especially true at Ericsson where a test may fail one day due to an environment problem and another day from a product fault. Although our anomaly analysis helps prioritize the test failures and gives a sense of how long a test has been failing, it does not help provide a precise reason and location for a fault.
%, e.g., whether the test is failed due to a newly introduced fault. 
To assist Ericsson testers in locating faults, we plan to conduct log analysis on tests. Our co-investigator Dr. Shang is an expert in log analysis. We currently have a masters student, Amar, who is partially funded by a MITACS and has started to collect and clean Ericsson logs.

Our preliminary analysis of test logs at Ericsson has revealed three challenges: 1) there is an overwhelming amount of detailed log information, 2) the complex testing environments and context information introduces noise and 3) the complex testing scenarios introduce noise. We plan our approach around these challenges. 

\begin{enumerate}

\item Data collection: We plan to extract all available test data including event streams, counters, and logs. In order to assist in understanding the complex testing environments, we extract the units from the data, \ie which test base station nodes are connected to which test mobile devices.

\item Log abstraction: We plan to abstract logs in order to reduce the contextual noise. Logs contain static and dynamic information. The static information is specific to each particular event, while the dynamic information describes the event context. We plan to abstract logs into events by comparing vocabulary of logs and source code. The words that exist in the vocabulary of logs but not in the vocabulary of source code are considered dynamic values. By anonymize such dynamic values, we can abstract logs to eliminate contextual noise.

\item Event sequence generation: The large volume of logs makes it difficult
and time consuming to understand each of the individual lines in a log file. We
plan to generate event sequences in order to illustrate the execution flow of
the tests. The complex testing scenarios increase the variability of events in
similar execution flows. We compress event sequences based on testing units
to extract generalized event sequences and to remove irrelevant, redundant, and
highly variable event sequences.

\item Event sequence comparison: To localize faults using test log analysis, we compare the delta between a baseline sequence and the current test log. 1) we plan to use successful runs as a baseline and create log deltas with failed runs to locate the reasons a test is failing. 2) we plan to compare the test logs from the previous stable release, the baseline, with test runs from current development to localize regressions.

\item Fault localization: Based on the identified potential problematic event, we perform three types of fault localization. 
	\begin{itemize}
		\item Environmental fault localization. We examine the identified problematic events in different testing environments. For example, we calculate the probability of observing the problematic events by varying the test base stations and mobile devices. If the events appear frequently in a special type of test base station or mobile device, we locate the fault for this environmental configuration.
		
		\item Source code fault localization. With the environmental faults identified in the previous step, we are able to find the source code that generate the log events. Dr. Shang has proposed a technique to link log lines to source code~\cite{Shang:2014:ULL:2705615.2706065}. We first leverage Dr. Shang's approach to locate the source code where the problematic event is generated. Given the complexity of Ericsson's systems, we want to recovered an execution profile of the systems (e.g., control and data flow) when the problematic event is generated. To recover a detailed execution profile, we propose a novel technique that identifies source code that can impact the logs. For instance, we would map the variables in the source code to the dynamic values in the log lines, and we would map conditional statements to the appearance of log lines. We plan to apply such technique on all the log lines in the problematic event sequence. With such an detailed execution profile of the system, we can assists developers in automatically locating and future diagnosing the faults.
	%	 we plan to map the dynamic values in the log lines with the variables in the source code. For example, by observing a log line as ``Error, retry$=$10'', we would like to link the number ``10'' to a variable in the source, such as ``int retryNumber''. By data flow analysis on the variable, we can have rich knowledge about the context of the execution. In addition, we recover a control flow of the problematic event. By analyzing the control flow, we can have the knowledge of the values of condition statements that may lead to the problematic event.
		
		\item Historical fault localization. Many faults are regression that have been observed or fixed in the past. We plan to store the event sequences and problematic events related to each fault. When a new problematic event is identified, we will use historical data to determine if it is already a known location. In addition, the people who resolved prior faults can be suggested as candidates to fix the regression fault.
		
	\end{itemize}
\end{enumerate}

%We plan two evaluation plans to measure the success of our approach. 
%\noindent \textbf{Localizing injected faults.} We plan to evaluate our approaching by injecting faults into the system. We inject common faults (including environmental faults and functional faults) that are priorly identified by practitioners into the system. Then we leverage our approach to perform fault localization. For the environmental faults, we examine whether we can identify the particular environment that has the fault. For the functional faults, we examine whether the context of the source code that is localized by our approach can unveil root cause of the fault. For every injected fault, we examine the prior fault that is located by our historical fault localization to understand whether the historical knowledge can assist in diagnosing the fault. To have a comprehensive evaluation of our approach, we plan to inject faults into systems in Ericsson as well as open source system software, such as Hadoop.

In contrast to previous works that use fault injection~\cite{Shang:2013:ADB:2486788.2486842}, we cannot use this technique to evaluate our approach because Ericsson's test environment is expensive and used at capacity. We plan two evaluations: a simulation and a deployment at Ericsson.

\noindent \textbf{Simulation to determine effectiveness.} We plan to use the information extracted from logs to locate the change location of faults found in the past. With this information, we will determine if our log analysis would have suggested the same location as that found by developers. We will evaluate efficiency in terms of the number of files and failed test would have to examine to locate the fault with and without our approach.
 
\noindent \textbf{Evaluating by deploying our approach into practice.} We plan to evaluate our approach with the testers at Ericsson. We deploy our approach in the real testing environment in Ericsson. For every fault from the testing environment, we provide our fault localization, and we record the actual fix of the fault. We compare the actual fix of the fault with our suggested fault localization. We want to examine: 1) how often our approach gives accurate fault localization and 2) whether the information provided by our approach would help speed up the diagnose and fix of the fault.

% oops should have used this list:
%1. Abstracting logs into a sequence of events to illustrate the execution flow of the tests.
%2. Compare event sequences to determine whether the failed test are due to new root causes or existing ones.
%3. Linking logs to codes to identify/scope down? the scenarios (root causes) of the failed test.

Our first novel contribution is to combine both run-time system behaviour during test (i.e., logs) and test results (i.e., pass or failure of the test) to provide actionable suggestions in the form of fault localization to practitioners. Similar approaches have been successful applied by Shang~\cite{Shang:2013:ADB:2486788.2486842} to compare the logs from test and production environments. In Ericsson's context, we do not have the production logs, so we must change our comparisons to involve baselines from previous test logs from other releases and successful and unsuccessful runs. Secondly, we consider the run-time system behaviour during test as a historical repository. Such system behaviour consists of rich information of the system during execution. We believe the knowledge from learning and analyzing the historical behaviour of the system are of huge benefits to software development and operation.

%\todo{Ian: further novel aspects include ...}
